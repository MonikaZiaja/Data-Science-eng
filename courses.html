<!doctype html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700&amp;subset=latin-ext" rel="stylesheet">
    <link rel="stylesheet" href="css/style.css">
    <link rel="stylesheet" href="css/courses.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.3/css/all.css"
        integrity="sha384-UHRtZLI+pbxtHCWp1t77Bi1L4ZtiqrqD80Kn4Z8NTSRyMA2Fd33n5dQ8lWUE00s/" crossorigin="anonymous">
    <title>Data Science</title>
</head>

<body>
    <div class="content"><button class="arrowUp"><i class="fas fa-arrow-up"></i></button>
        <nav class="mainNav">
            <div class="mainNav__logo"><img class="mainNav__logo--logoUwr" src="img/uwr.png" /> <i
                    class="fas fa-bars"></i> <i class="fas fa-times off"></i></div>
            <ul class="mainNav__list off"><a href="index.html">
                    <li class="mainNav__item" id="section--1">Data Science</li>
                </a><a href="courses.html">
                    <li class="mainNav__item" id="section--1">Courses</li>
                </a><a href="staff.html">
                    <li class="mainNav__item" id="section--1">Staff</li>
                </a></ul>
        </nav>
        <header class="mainHeader">
            <div class="mainHeader__box">
                <div class="mainHeader__box--left">
                    <!-- <h4 class="mainHeader__title--smaller">New<h4 class="mainHeader__title--smaller">specialisation</h4>
                    </h4> -->
                </div>
                <div class="mainHeader__box--right">
                    <h1 class="mainHeader__title--bigger">Data Science</h1>
                </div>
            </div><button class="btn--transparent mainHeader__btn--transparent">Read more</button>
        </header>
        <section data-section="section--4" class="section section__4">
            <section class="courses__section--obligatory courses__section">
                <h1 class="title__courses title__courses--obligatory">Mandatory Core Courses</h1>
                <p class="txt__courses">These three core courses are mandatory for all students. Their role is to give a
                    basic toolbox for
                    future data scientists and provide solid mathematical foundations that enable you to take more
                    advanced and applied courses. We expect students to take them in the first two semesters.</p>
                <h1 class="course__title course__title--obligatory">Numerical Optimization</h1>
                <div class="course">
                    <section class="course__descript">
                        <p class="course__txt">This course is a detailed survey of optimization from both a
                            computational and
                            theoretical perspective. Theoretical topics include convex sets, convex functions,
                            optimization problems, least-squares, linear and quadratic programs, optimality
                            conditions, and duality theory. Special emphasis is put on scalable numerical methods
                            for analyzing and solving linear programs (e.g. simplex), general smooth unconstrained
                            problems (e.g. first-order and second-order methods), quadratic programs (e.g. linear
                            least squares), general smooth constrained problems (e.g. interior-point methods), as

                            well as, a family of non-smooth problems (e.g. ADMM method). The applications in data
                            sciences, such as machine learning, model fitting, and image processing, will be
                            discussed. The computational part covers the following algorithms: gradient method,
                            quasi-Newton methods, proximal gradient method, Nesterov’s accelerated gradient
                            method, augmented Lagrangian method, alternating direction method of multipliers,
                            block coordinate descent method and stochastic gradient descent method. Students
                            complete hands-on exercises using high-level numerical software.</p>
                        <div class="displayRow">
                            <!-- <button class="course__tag">sem 1</button>  -->
                            <button class="course__tag">2019/20</button>
                        </div>
                    </section>
                    <section class="course__staff">
                        <div class="staff--1">
                            <div class="staff__img"></div><a href="staff.html" class="staff__title">Waldemar Hebisch</a>
                        </div>
                        <div class="staff--1">
                            <div class="staff__img"></div><a href="staff.html" class="staff__title">Rafał Nowak</a>
                        </div>
                    </section>
                </div>
                <h1 class="course__title course__title--obligatory">Machine Learning</h1>
                <div class="course">
                    <section class="course__descript">
                        <p class="course__txt">This course provides the fundamentals of designing programs that
                            implement a data-
                            driven, rather than hand-implemented behavior. The course provides a gentle
                            introduction of the topic, but strives to provide enough details and intuitions to explain
                            state-of-the-art ML approaches: ensembles of Decision Trees (Boosted Trees, Random
                            Forests) and Neural Networks. Starting with simple linear and Bayesian models, we
                            proceed to learn the concepts of trainable models, selecting the best model based on
                            data, practical and theoretical ways of estimating model performance on new data, and
                            the difference between discriminative and generative training. The course introduces
                            mainstream algorithms for classification and regression including linear models, Naive
                            Bayes, trees, ensembles, and matrix factorizations for recommendation systems.
                            Practical sessions provide a hands-on experience with the methods.</p>
                        <button class="course__tag">2019/20</button>
                    </section>
                    <section class="course__staff">
                        <div class="staff--1">
                            <div class="staff__img">
                            </div><a href="staff.html" class="staff__title">Jan Chorowski</a>
                        </div>
                    </section>
                </div>
                <h1 class="course__title course__title--obligatory">Statistical Learning</h1>
                <div class="course">
                    <section class="course__descript">
                        <p class="course__txt">This course is mainly devoted to the analysis of &#39;&#39;fat&#39;&#39;
                            data sets with large number of
                            variables. In this situation the effective analysis requires techniques of dimensionality
                            reduction. We discuss classical and modern methods of dimensionality reduction in the
                            context of supervised and unsupervised learning. Specifically, we consider principal
                            component analysis, subspace clustering and Gaussian graphical models (unsupervised
                            learning) and different penalized methods for building predictive models (supervised
                            learning) including ridge regression, LASSO and SLOPE. The emphasis is be placed on
                            understanding the statistical properties of discussed methodology through theoretical
                            results, simulation studies and analysis of real data.</p>
                        <!-- <button class="course__tag">sem 1</button> -->
                    </section>
                    <section class="course__staff">
                        <div class="staff--1">
                            <div class="staff__img"></div>
                            <a href="staff.html" class="staff__title">Małgorzata Bogdan</a>
                        </div>
                    </section>
                </div>
            </section>
            <section class="courses__section courses__section--core">
                <h1 class="title__courses title__courses--core">Elective Core Courses</h1>
                <p class="txt__courses">To gain more specialized knowledge in different areas of data science, students
                    have to
                    take at least four of the following fundamental elective courses. Each course is taught at
                    least once per two years (a semester with the next edition is given at course description).
                    Topics are subject to slight changes and updates, which reflect the evolution of the data
                    science field and varying requirements from the job market.</p>
                <h1 class="course__title course__title--core">Methods of classification and dimensionality reduction
                </h1>
                <div class="course">
                    <section class="course__descript">
                        <p class="course__txt">The course provides a survey of dimensionality reduction (feature
                            extraction) and
                            classification methods. Dimensionality reduction enhances the performance of computer
                            vision and machine learning-based approaches, it allows to represent the data in a more
                            efficient way, it allows to visualise high-dimensional data. Among others, we study
                            principal component analysis (PCA), non-negative matrix factorization (NMF),
                            independent component analysis (ICA), t-distributed Stochastic Neighbour Embedding (t-
                            SNE). Concerning classification methods, we study many classical
                            &quot;shallow-learning&quot;

                            classifiers, e.g., nearest neighbours, naive Bayes, support vector machine (SVM), linear
                            and quadratic discriminant analysis (LDA and QDA), decision trees. Though all details
                            are provided for most methods, we put a strong emphasis on intuition and practical
                            applications: we discuss (and apply the acquired knowledge to various practical
                            problems in lab classes), e.g., classification of multidimensional data (including time
                            series, images and texts), image compression, topic recovery, recommendation systems.</p>
                        <button class="course__tag">2019/20</button>
                    </section>
                    <section class="course__staff">
                        <div class="staff--1">
                            <div class="staff__img"></div><a href="staff.html" class="staff__title">Paweł Lorek</a>
                        </div>
                    </section>
                </div>
                <h1 class="course__title course__title--core">Simulations and algorithmic applications of Markov chains
                </h1>
                <div class="course">
                    <section class="course__descript">
                        <p class="course__txt">The course is devoted to discrete time Markov chains with finite state
                            space. We gently
                            start with fundamentals (stationary distributions, transition-matrix based simulations,
                            reversibility) and go through monte carlo Markov chain methods (MCMC, a class of
                            algorithms providing one of the currently most popular methods for simulating
                            complicated stochastic systems); rate of convergence methods (&quot;how many times should
                            we shuffle a deck of cards?&quot; — we study coupling methods, strong stationary times,
                            strong stationary duality, inequalities (Cheeger and Poincaré) for bounding the second-
                            largest eigenvalue of a transition matrix); coupling from the past (CFTP) algorithm
                            (improvement of standard MCMC, allows to obtain an unbiased sample from given
                            distribution on huge state space, e.g., Ising model); estimating winning probabilities in
                            gambler ruin-like problems (first step analysis and Siegmund duality); simulated
                            annealing (a widely used randomized algorithm for various optimization problems);
                            basics of hidden markov models (HMM, a popular machine learning algorithm, e.g., for
                            speech recognition); randomized polynomial time approximation schemes (MCMC-
                            originated algorithm for approximating &quot;the answer&quot; to NP-hard related problem,
                            e.g.,
                            graph coloring).</p><button class="course__tag">2020/21</button>
                    </section>
                    <section class="course__staff">
                        <div class="staff--1">
                            <div class="staff__img"></div><a href="staff.html" class="staff__title">Paweł Lorek</a>
                        </div>
                    </section>
                </div>
                <h1 class="course__title course__title--core">Natural language processing</h1>
                <div class="course">
                    <section class="course__descript">
                        <p class="course__txt">The aim of the course is to discuss the methods used in the analysis and processing of
                                texts in natural languages, with particular emphasis on results that can be translated into
                                effective implementation. We consider both classical methods of language modelling
                                (Hidden Markov Models, (Probabilistic) Context Free Grammars, Finite State
                                Transducers) and modern, neural networks based approaches: RNN, LSTM,
                                Convolutional Neural Networks and Transformer. We show several applications of this
                                methods, including POS-tagging, dependency parsing, Named Entity Recognition,
                                Machine Translation, and Natural Language Generation.</p>
                                <!-- <button class="course__tag">sem 1</button> -->
                    </section>
                    <section class="course__staff">
                        <div class="staff--1">
                            <div class="staff__img"></div><a href="staff.html" class="staff__title">Paweł Rychlikowski</a>
                        </div>
                    </section>
                </div>
                <h1 class="course__title course__title--core">Text mining</h1>
                <div class="course">
                    <section class="course__descript">
                        <p class="course__txt">In this course, we cover basic and more advanced information retrieval techniques. We
                                also discuss data mining methods applied to texts. We discuss how to implement from
                                scratch efficient systems gathering information from large text corpora. We analyze in
                                detail several variants of word embeddings, and their use in computing texts similarity.
                                We discuss text classification methods, flat and hierarchical clusterization, automatic
                                summarisation, text comprehension methods and question answering.</p>
                                <!-- <button class="course__tag">sem 1</button> -->
                    </section>
                    <section class="course__staff">
                        <div class="staff--1">
                            <div class="staff__img"></div><a href="staff.html" class="staff__title">Paweł Rychlikowski</a>
                        </div>
                    </section>
                </div>
                <h1 class="course__title course__title--core">Advanced Data Mining</h1>
                <div class="course">
                    <section class="course__descript">
                        <p class="course__txt">This course focuses on advanced data mining algorithms for processing big, complex
                                and unstructured data. It mainly concerns recommendation systems, dimensionality
                                reduction with neighborhood embedding, temporal data mining and decision support
                                systems. In recommendation systems, various approaches from simple collaborative
                                filtering to advanced matrix factorization are presented and discussed in the context of
                                their practical relevance, concerning not only the popular MSE or MAE measures, but
                                
                                also the coverage, diversity, and novelty of recommendations. In temporal data mining,
                                beside the analysis of regular time series with machine learning methods, such as
                                Support Vector Regression and Neural Networks, unstructured temporal data are
                                studied. Student projects concern unstructured datasets, such as irregular
                                multidimensional time series, GPS tracks or medical images.</p><button
                            class="course__tag">2020/21</button>
                    </section>
                    <section class="course__staff">
                        <div class="staff--1">
                            <div class="staff__img"></div><a href="staff.html" class="staff__title">Piotr Wnuk-Lipiński</a>
                        </div>
                    </section>
                </div>
                <h1 class="course__title course__title--core">Tools and methods in big data processing</h1>
                <div class="course">
                    <section class="course__descript">
                        <p class="course__txt">This course covers the technical background useful in processing large amounts of data
                                in a distributed environment. We discuss cloud computing basics and then introduce
                                Hadoop Distributed File System (HDFS) architecture and MapReduce programming
                                paradigm. The course studies in-depth Apache Spark and its ecosystem including Spark
                                programming with Scala, Spark SQL, Spark graph processing framework GraphX, also
                                TinkerPop and Gremlin traversals. Finally, some time is spent on stream processing
                                technologies such as Apache Kafka and Spark Streaming.</p><button
                            class="course__tag">2020/21</button>
                    </section>
                    <section class="course__staff">
                        <div class="staff--1">
                            <div class="staff__img"></div><a href="staff.html" class="staff__title">Piotr Wieczorek</a>
                        </div>
                    </section>
                </div>
            </br>
                <h1 class="course__title course__title--core">Theory and Analysis of Large Data Sets - Małgorzata Bogdan</h1>
                <!-- <div class="course">
                    <section class="course__descript">
                        <p class="course__txt">Lorem ipsum dolor sit amet consectetur adipisicing elit. Sequi ipsum, est
                            dolor dicta alias animi perferendis explicabo sunt suscipit sit?</p><button
                            class="course__tag">sem 1</button>
                    </section>
                    <section class="course__staff">
                        <div class="staff--1">
                            <div class="staff__img"></div><a href="staff.html" class="staff__title">Jan Kowalski</a>
                        </div>
                    </section>
                </div> -->
            </br>
                <h1 class="course__title course__title--core">Neural Networks - Jan Chorowski</h1>
                <!-- <div class="course">
                    <section class="course__descript">
                        <p class="course__txt">Lorem ipsum dolor sit amet consectetur adipisicing elit. Sequi ipsum, est
                            dolor dicta alias animi perferendis explicabo sunt suscipit sit?</p><button
                            class="course__tag">sem 1</button>
                    </section>
                    <section class="course__staff">
                        <div class="staff--1">
                            <div class="staff__img"></div><a href="staff.html" class="staff__title">Jan Kowalski</a>
                        </div>
                    </section>
                </div> -->
            </br>
                <h1 class="course__title course__title--core">Numerical programming tools and methods - Jan Chorowski</h1>
                <!-- <div class="course">
                    <section class="course__descript">
                        <p class="course__txt">Lorem ipsum dolor sit amet consectetur adipisicing elit. Sequi ipsum, est
                            dolor dicta alias animi perferendis explicabo sunt suscipit sit?</p><button
                            class="course__tag">sem 1</button>
                    </section>
                    <section class="course__staff">
                        <div class="staff--1">
                            <div class="staff__img"></div><a href="staff.html" class="staff__title">Jan Kowalski</a>
                        </div>
                    </section>
                </div> -->
            </br>
                <h1 class="course__title course__title--core">Seminar: probabilistic graphical models</h1>
                <!-- <div class="course">
                    <section class="course__descript">
                        <p class="course__txt">Lorem ipsum dolor sit amet consectetur adipisicing elit. Sequi ipsum, est
                            dolor dicta alias animi perferendis explicabo sunt suscipit sit?</p><button
                            class="course__tag">sem 1</button>
                    </section>
                    <section class="course__staff">
                        <div class="staff--1">
                            <div class="staff__img"></div><a href="staff.html" class="staff__title">Jan Kowalski</a>
                        </div>
                    </section>
                </div> -->
            </br>
                <h1 class="course__title course__title--core">Team Project: TBA</h1>
                <!-- <div class="course">
                    <section class="course__descript">
                        <p class="course__txt">Lorem ipsum dolor sit amet consectetur adipisicing elit. Sequi ipsum, est
                            dolor dicta alias animi perferendis explicabo sunt suscipit sit?</p><button
                            class="course__tag">sem 1</button>
                    </section>
                    <section class="course__staff">
                        <div class="staff--1">
                            <div class="staff__img"></div><a href="staff.html" class="staff__title">Jan Kowalski</a>
                        </div>
                    </section>
                </div> -->
            </br>
            </section>
            <section class="courses__section courses__section--additional">
                <h1 class="title__courses title__courses--additional">Additional courses</h1>
                <p class="txt__courses">Students may enrich their competences by taking additional courses that are not directly data
                        science related, but could give them competitive edge in their future careers, providing them, for
                        example, with unique skills in optimization or algorithms. While the students may freely choose any
                        master-level courses taught at the department, the list below contains courses that are particularly
                        suited for the data science students.</p>
                <h1 class="course__title course__title--additional">Algorithmic game theory. Jarosław Byrka</h1>
                <!-- <div class="course">
                    <section class="course__descript">
                        <p class="course__txt">Lorem ipsum dolor sit amet consectetur adipisicing elit. Sequi ipsum, est
                            dolor dicta alias animi perferendis explicabo sunt suscipit sit?</p><button
                            class="course__tag">sem 1</button>
                    </section>
                    <section class="course__staff">
                        <div class="staff--1"><a href="staff.html" class="staff__title">Jan Kowalski</a></div>
                    </section>
                </div> -->
            </br>
                <h1 class="course__title course__title--additional">Algorithms on strings. Paweł Gawrychowski</h1>
            </br>
                <h1 class="course__title course__title--additional">Artificial intelligence in games. Jan Kowalski</h1>
            </br>
                <h1 class="course__title course__title--additional">Approximation algorithms. Katarzyna Paluch</h1>
            </br>
                <h1 class="course__title course__title--additional">Category theory. Maciej Piróg</h1>
            </br>
                <h1 class="course__title course__title--additional">Combinatorial optimization. Katarzyna Paluch</h1>
            </br>
                <h1 class="course__title course__title--additional">Combinatorics. Grzegorz Stachowiak</h1>
            </br>
                <h1 class="course__title course__title--additional">Computational complexity. Krzysztof Loryś</h1>
            </br>
                <h1 class="course__title course__title--additional">Computational geometry. Paweł Gawrychowski</h1>
            </br>
                <h1 class="course__title course__title--additional">Cryptography. Grzegorz Stachowiak</h1>
            </br>
                <h1 class="course__title course__title--additional">Data compression. Tomasz Jurdziński</h1>
            </br>
                <h1 class="course__title course__title--additional">Distributed algorithms. Tomasz Jurdziński</h1>
            </br>
                <h1 class="course__title course__title--additional">Interactive theorem proving in Coq. Małgorzata Biernacka and Filip Sieczkowski</h1>
            </br>
            <h1 class="course__title course__title--additional">Online algorithms. Marcin Bieńkowski</h1>
            </br>
            <h1 class="course__title course__title--additional">Photorealistic computer graphics. Andrzej Łukaszewski</h1>
            </br>
            <h1 class="course__title course__title--additional">Program analysis. Witold Charatonik</h1>
            </br>
            <h1 class="course__title course__title--additional">Randomized algorithms. Marek Piotrów</h1>
            </br>
            <h1 class="course__title course__title--additional">Semantics of programming languages. Dariusz Biernacki and Filip Sieczkowski</h1>
            </br>
            <h1 class="course__title course__title--additional">Theory of linear and integer programming. Jarosław Byrka</h1>
            </br>
            <h1 class="course__title course__title--additional">UNIX kernel structure. Krystian Bacławski</h1>
            </br>
            <h1 class="course__title course__title--additional">Verification of programs. Małgorzata Biernacka and Witold Charatonik</h1>
            </br>
            <h1 class="course__title course__title--additional">Word equations. Artur Jeż</h1>
        </br>
            <h1 class="course__title course__title--additional">Wstęp do symulacji i metod Monte Carlo. Paweł Lorek</h1>
        </br>    
        </section>
        </section>
        <section data-section="section--contact" class="section section__contact">
            <h1 class="title title__contact">Contact</h1>
            <div class="contact__content">
                <div class="contact__section">
                    <h2 class="title__contact--inside">Institute of Mathematics</h2>
                    <p><i class="fas fa-map-marker-alt contactFont"></i>pl. Grunwaldzki 2/4</p>
                    <p class="txt__contact--wf">50-384 Wrocław</p>
                    <p><i class="fas fa-envelope contactFont"></i>rekrutacja@math.uni.wroc.pl</p>
                </div>
                <div class="contact__section">
                    <h2 class="title__contact--inside">Deanery</h2>
                    <p><i class="fas fa-map-marker-alt contactFont"></i>ul. Joliot-Curie 15</p>
                    <p class="txt__contact--wf">50-383 Wrocław</p>
                    <p><i class="fas fa-phone contactFont"></i>71 375 7895</p>
                </div>
            </div>
        </section>
        <footer class="siteFooter"></footer>
        <footer class="crFooter">Copyright &copy 2019 by Instytut Matematyczny Uniwersytetu Wrocławskiego. Created by
            Monika Ziaja.</footer>
    </div>
    <script src="https://code.jquery.com/jquery-3.1.1.min.js"></script>
    <script src="js/script.js"></script>
    <script src="js/parallax.js"></script>
</body>

</html>